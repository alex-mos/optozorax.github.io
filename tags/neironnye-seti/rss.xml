<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
      <title>optozorax.blog - нейронные-сети</title>
        <link>https://testzorax.github.io/</link>
        <description>Мои програмульки и результаты их работы</description>
        <generator>Zola</generator>
        <language>ru</language>
        <atom:link href="https://testzorax.github.io/tags/neironnye-seti/rss.xml" rel="self" type="application/rss+xml"/>
        <lastBuildDate>Mon, 06 Jan 2020 00:00:00 +0000</lastBuildDate>
        <item>
            <title>Произвольная нейросеть</title>
            <pubDate>Mon, 06 Jan 2020 00:00:00 +0000</pubDate>
            <link>https://testzorax.github.io/p/arbitrary-nn/</link>
            <guid>https://testzorax.github.io/p/arbitrary-nn/</guid>
            <description>&lt;h1 id=&quot;vvedenie&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#vvedenie&quot;&gt;#&lt;&#x2F;a&gt;Введение&lt;&#x2F;h1&gt;
&lt;p&gt;У вас не возникало ощущения что все текущие нейросети какие-то слишком линейные? Посмотрим, например, на перцептрон:&lt;&#x2F;p&gt;
&lt;figure&gt;
&lt;div class=&quot;magnifier-container img-one&quot;&gt;
&lt;img
    class=&quot;not-default full-screen-img&quot;
    width=&quot;395&quot;
    height=&quot;354&quot;
    src=&quot;&amp;#x2F;processed_images&amp;#x2F;5faa13a2b78bbd8600.webp&quot; 
    onclick=&quot;full_screen(&#x27;perceptron.png&#x27;)&quot;
    onauxclick=&quot;full_screen_new_page(&#x27;perceptron.png&#x27;)&quot;&gt;
&lt;div class=&quot;magnifier-display&quot;&gt;
&lt;img class=&quot;magnifier&quot; src=&quot;&#x2F;ico&#x2F;magnifier.svg&quot;&gt;&lt;div class=&quot;magnifier-info&quot;&gt;×1&lt;br&gt;png&lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;figcaption&gt;&lt;a href=&quot;https:&#x2F;&#x2F;ru.wikipedia.org&#x2F;wiki&#x2F;%D0%9F%D0%B5%D1%80%D1%86%D0%B5%D0%BF%D1%82%D1%80%D0%BE%D0%BD#&#x2F;media&#x2F;%D0%A4%D0%B0%D0%B9%D0%BB:Perceptron-ru.svg&quot;&gt;Источник&lt;&#x2F;a&gt;&lt;&#x2F;figcaption&gt;
&lt;&#x2F;figure&gt;
&lt;p&gt;Или на многослойную нейронную сеть:&lt;&#x2F;p&gt;
&lt;figure&gt;
&lt;div class=&quot;magnifier-container img-one&quot;&gt;
&lt;img
    class=&quot;not-default full-screen-img&quot;
    width=&quot;958&quot;
    height=&quot;455&quot;
    src=&quot;&amp;#x2F;processed_images&amp;#x2F;87116efccecb22a700.webp&quot; 
    onclick=&quot;full_screen(&#x27;multilayered.png&#x27;)&quot;
    onauxclick=&quot;full_screen_new_page(&#x27;multilayered.png&#x27;)&quot;&gt;
&lt;div class=&quot;magnifier-display&quot;&gt;
&lt;img class=&quot;magnifier&quot; src=&quot;&#x2F;ico&#x2F;magnifier.svg&quot;&gt;&lt;div class=&quot;magnifier-info&quot;&gt;×1&lt;br&gt;png&lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;figcaption&gt;&lt;a href=&quot;https:&#x2F;&#x2F;ru.wikipedia.org&#x2F;wiki&#x2F;%D0%9F%D0%B5%D1%80%D1%86%D0%B5%D0%BF%D1%82%D1%80%D0%BE%D0%BD#&#x2F;media&#x2F;%D0%A4%D0%B0%D0%B9%D0%BB:Neuro.PNG&quot;&gt;Источник&lt;&#x2F;a&gt;&lt;&#x2F;figcaption&gt;
&lt;&#x2F;figure&gt;
&lt;p&gt;Когда я только изучал эту тему, у меня была такая мысль:&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;Почему в них сигнал распространяется только в направлении слева-направо? Где циклы? Как без циклов возможны сложные вычисления?&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;Но на самом деле нейросети и не обязаны быть произвольными. Уже в таком виде они справляются с большим количеством задач. &lt;&#x2F;p&gt;
&lt;p&gt;Кстати, благодаря этой линейнойсти мы можем выжимать максимум из наших текущих вычислительных мощностей, используя очень большие нейросети. На них сигнал распространяется без всяких циклов, а значит это быстрее вычислять. &lt;&#x2F;p&gt;
&lt;p&gt;Да и для таких нейросетей придумали в своё время алгоритм обратного распространения ошибки.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;primer-proizvol-noi-neiroseti&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#primer-proizvol-noi-neiroseti&quot;&gt;#&lt;&#x2F;a&gt;Пример произвольной нейросети&lt;&#x2F;h1&gt;
&lt;p&gt;Не знаю откуда мы все это берём, но мы точно знаем, что в мозгу не могут быть такие однонаправленные связи, там полюбому должны присутсововать циклы и прочие очень сложные штуки. Нейросеть в нашем мозгу должна выглядеть примерно так:&lt;&#x2F;p&gt;
&lt;div class=&quot;magnifier-container img-one&quot;&gt;
&lt;img
    class=&quot;not-default full-screen-img&quot;
    width=&quot;932&quot;
    height=&quot;482&quot;
    src=&quot;&amp;#x2F;processed_images&amp;#x2F;16889bdb07c4ab4a00.webp&quot; 
    onclick=&quot;full_screen(&#x27;arbitrary_nn.png&#x27;)&quot;
    onauxclick=&quot;full_screen_new_page(&#x27;arbitrary_nn.png&#x27;)&quot;&gt;
&lt;div class=&quot;magnifier-display&quot;&gt;
&lt;img class=&quot;magnifier&quot; src=&quot;&#x2F;ico&#x2F;magnifier.svg&quot;&gt;&lt;div class=&quot;magnifier-info&quot;&gt;×1&lt;br&gt;png&lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;p&gt;То есть как просто простой направленный граф без всяких ограничений.&lt;&#x2F;p&gt;
&lt;p&gt;Очевидно, что такая нейросеть должна обладать возможность что-то &amp;quot;запоминать&amp;quot; на краткосрочный период, делать цикличные движения. Такая нейросеть идеально подходит для использования в агентах внутри симуляций.&lt;&#x2F;p&gt;
&lt;p&gt;Если мы симулируем агента в какой-то среде, то мы должны напрямую симулировать процесс &amp;quot;движения сигнала&amp;quot;, задавать какие-то ограничения по количество этих передвижений сигнала для одного шага, накапливать результат на красных выходных нейронах и что-то подобное.&lt;&#x2F;p&gt;
&lt;p&gt;Я не стал на этом изображении расставлять веса нейронных связей, чтобы не загромождать изображение, но по факту они там должны быть.&lt;&#x2F;p&gt;
&lt;p&gt;Кстати, произвольная нейросеть была использована в этом видео:&lt;&#x2F;p&gt;
&lt;center&gt;
&lt;iframe src=&quot;https:&#x2F;&#x2F;www.youtube-nocookie.com&#x2F;embed&#x2F;5lJuEW-5vr8&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen style=&quot;width: 560px; height: 315px;&quot;&gt;&lt;&#x2F;iframe&gt;
&lt;&#x2F;center&gt;
&lt;p&gt;И ведь действительно, интуитивно очевидно, что для симуляции агентов, пытающихся развиваться в виртуальном или реальном мире, надо использовать максимально общий класс нейросетей - произвольные! &lt;&#x2F;p&gt;
&lt;p&gt;Меня очень долго волновала проблема, почему нигде в интернете я не могу найти как учёные используют такие прозвольные нейросети, неужто целая категория нейронных сетей берёт и простаивает??? Значит могу прийти я со своими произвольными нейросетями и взорвать науку?!&lt;&#x2F;p&gt;
&lt;p&gt;К сожалению, нет.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;rekkurentnaia-neironnaia-set&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#rekkurentnaia-neironnaia-set&quot;&gt;#&lt;&#x2F;a&gt;Реккурентная нейронная сеть&lt;&#x2F;h1&gt;
&lt;p&gt;Чтобы понять дальнейшее повествование, надо понять что такое реккурентная нейросеть. Для ознакомления рекомендую это видео:&lt;&#x2F;p&gt;
&lt;center&gt;
&lt;iframe src=&quot;https:&#x2F;&#x2F;www.youtube-nocookie.com&#x2F;embed&#x2F;ADcu9rWK_3I&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen style=&quot;width: 560px; height: 315px;&quot;&gt;&lt;&#x2F;iframe&gt;
&lt;&#x2F;center&gt;
&lt;p&gt;Тут расскажут не только как это работает в общем виде, но ещё и расскажут про одну очень хитрую современную архитектуру LSTM.&lt;&#x2F;p&gt;
&lt;p&gt;Ну, или можете это проигнорировать (всё-таки час идёт) и просто попытаться понять суть из контекста.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;svodim-proizvol-nuiu-neiroset-k-rekkurentnoi&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#svodim-proizvol-nuiu-neiroset-k-rekkurentnoi&quot;&gt;#&lt;&#x2F;a&gt;Сводим произвольную нейросеть к реккурентной&lt;&#x2F;h1&gt;
&lt;p&gt;Сначала пронумеруем все нейроны.&lt;&#x2F;p&gt;
&lt;div class=&quot;magnifier-container img-one&quot;&gt;
&lt;img
    class=&quot;not-default full-screen-img&quot;
    width=&quot;931&quot;
    height=&quot;481&quot;
    src=&quot;&amp;#x2F;processed_images&amp;#x2F;d21fc5fc32af109600.webp&quot; 
    onclick=&quot;full_screen(&#x27;arbitrary_nn_enumerated.png&#x27;)&quot;
    onauxclick=&quot;full_screen_new_page(&#x27;arbitrary_nn_enumerated.png&#x27;)&quot;&gt;
&lt;div class=&quot;magnifier-display&quot;&gt;
&lt;img class=&quot;magnifier&quot; src=&quot;&#x2F;ico&#x2F;magnifier.svg&quot;&gt;&lt;div class=&quot;magnifier-info&quot;&gt;×1&lt;br&gt;png&lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;p&gt;Затем уберём все связи, и расположим все нейроны сверху-вниз, и сделаем второй столбик-дубликат первого. Это показано на следующей картинке слева. &lt;&#x2F;p&gt;
&lt;p&gt;Теперь просто остаётся добавить связи, но добавлять будем таким образом, что связь может быть направлена только из левого столбика в правый. Результат показан на правой части картинки.&lt;&#x2F;p&gt;
&lt;div class=&quot;magnifier-container img-one&quot;&gt;
&lt;img
    class=&quot;not-default full-screen-img&quot;
    width=&quot;428&quot;
    height=&quot;806&quot;
    src=&quot;&amp;#x2F;processed_images&amp;#x2F;d1aa4d3e234ebbde00.webp&quot; 
    onclick=&quot;full_screen(&#x27;arbitrary_nn_two.png&#x27;)&quot;
    onauxclick=&quot;full_screen_new_page(&#x27;arbitrary_nn_two.png&#x27;)&quot;&gt;
&lt;div class=&quot;magnifier-display&quot;&gt;
&lt;img class=&quot;magnifier&quot; src=&quot;&#x2F;ico&#x2F;magnifier.svg&quot;&gt;&lt;div class=&quot;magnifier-info&quot;&gt;×1&lt;br&gt;png&lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;p&gt;Это и есть реккурентная нейросеть, мы свели всё к ней! Значит, реккурентная нейросеть способна представить любую топологию нейросети, и нет смысла изобретать свои собственные велосипеды.&lt;&#x2F;p&gt;
&lt;p&gt;Как видно, здесь слева не используются выходные нейроны, а справа не используются входные нейроны.&lt;&#x2F;p&gt;
&lt;p&gt;И действительно, если подумать как здесь протекают сигналы, это просто другой способ обозначения нейросети с произвольной архитектурой. Это даже напоминает матрицу смежности для представления графа. То есть можно визуализировать это так:&lt;&#x2F;p&gt;
&lt;div class=&quot;magnifier-container img-one&quot;&gt;
&lt;img
    class=&quot;not-default full-screen-img&quot;
    width=&quot;808&quot;
    height=&quot;798&quot;
    src=&quot;&amp;#x2F;processed_images&amp;#x2F;1b74f95829bf076c00.webp&quot; 
    onclick=&quot;full_screen(&#x27;matrix_nn.png&#x27;)&quot;
    onauxclick=&quot;full_screen_new_page(&#x27;matrix_nn.png&#x27;)&quot;&gt;
&lt;div class=&quot;magnifier-display&quot;&gt;
&lt;img class=&quot;magnifier&quot; src=&quot;&#x2F;ico&#x2F;magnifier.svg&quot;&gt;&lt;div class=&quot;magnifier-info&quot;&gt;×1&lt;br&gt;png&lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;p&gt;Так как веса не заданы, то можно просто обозначить наличие связи при помощи красного квадрата. И в таком виде очевидно, что входные и выходные данные надо представлять как вектор, а саму нейросеть как матрицу.&lt;&#x2F;p&gt;
&lt;p&gt;Кстати в таком виде невозможно обозначить больше чем одну связь из одной ноды в другую. Вообще не знаю зачем это может понадобиться, кроме как использовать разные функции активации, да и это тоже вполне бессмысленная вещь, так что оставим этот случай.&lt;&#x2F;p&gt;
&lt;div class=&quot;magnifier-container img-one&quot;&gt;
&lt;img
    class=&quot;not-default full-screen-img&quot;
    width=&quot;241&quot;
    height=&quot;81&quot;
    src=&quot;&amp;#x2F;processed_images&amp;#x2F;968306985082cb6500.webp&quot; 
    onclick=&quot;full_screen(&#x27;not_allowed.png&#x27;)&quot;
    onauxclick=&quot;full_screen_new_page(&#x27;not_allowed.png&#x27;)&quot;&gt;
&lt;div class=&quot;magnifier-display&quot;&gt;
&lt;img class=&quot;magnifier&quot; src=&quot;&#x2F;ico&#x2F;magnifier.svg&quot;&gt;&lt;div class=&quot;magnifier-info&quot;&gt;×1&lt;br&gt;png&lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;&#x2F;div&gt;
&lt;h1 id=&quot;pochemu-eto-luchshe&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#pochemu-eto-luchshe&quot;&gt;#&lt;&#x2F;a&gt;Почему это лучше&lt;&#x2F;h1&gt;
&lt;p&gt;И я даже скажу, что в таком виде произвольная нейросеть получается лучше, чем её изначальный интуитивный вид. Почему?&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Во-первых&lt;&#x2F;strong&gt; вы можете использовать всю мощь, что развилась вокруг реккурентных нейросетей, будь то софт для их обучения или множество научных работ, например про преодоление взрыва градиентов.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Во-вторых&lt;&#x2F;strong&gt; представлять её таким образом в памяти вычислительно эффективней. Предположим как бы вы стали реализовывать класс, обрабатывающий нейросеть, которую мы нарисовали в самом начале? Наверняка бы делали напрямик: хранили бы где-то массив импульсов, хранили бы граф связей и перемещали бы импульсы по этому графу. А распараллеливать это добро очень сложно.&lt;&#x2F;p&gt;
&lt;p&gt;А реккурентные нейросети очень легко представляются матрицей, которую можно просто умножать на вектор чисел. Это даже с точки зрения кэша процессора куда эффективнее. Тем более для умножения матриц уже написали вагон и маленькую тележку сверх-быстрых параллельных библиотек, не говоря о умножении матриц на видеокарте.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;kak-ia-prishiol-k-etoi-idee&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#kak-ia-prishiol-k-etoi-idee&quot;&gt;#&lt;&#x2F;a&gt;Как я пришёл к этой идее&lt;&#x2F;h1&gt;
&lt;p&gt;Совершенно случайно. Нигде об этом прямым текстом не пишется. Мне непонятно, почему, ведь это очень важно! Можно же было просто написать:&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;Реккурентная нейронная сеть позволяет имитировать нейросеть, представляющую из себя произвольный граф.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;h1 id=&quot;zakliuchenie&quot;&gt;&lt;a class=&quot;anchor&quot; href=&quot;#zakliuchenie&quot;&gt;#&lt;&#x2F;a&gt;Заключение&lt;&#x2F;h1&gt;
&lt;p&gt;Так что не взорвём мы науку с нашими произвольными нейросетями, они уже существовали до нас, но скрывались под другим названием, просто никто толком не знал, что это они.&lt;&#x2F;p&gt;
&lt;p&gt;А теперь в следующий раз, когда надумаете писать свою эволюцию агентов с произвольными нейросетями и аниме-тянками, вы не наступите на грабли велосипедостроения, и сможете использовать отлаженный и оптимизированный инструментарий реккурентных нейросетей!&lt;&#x2F;p&gt;
&lt;p&gt;Кстати, приглашаю всех людей, заинтересованных в симуляции эволюции, в чатик в телеграме: &lt;a href=&quot;https:&#x2F;&#x2F;t.me&#x2F;emergevolution&quot;&gt;https:&#x2F;&#x2F;t.me&#x2F;emergevolution&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</description>
        </item>
    </channel>
</rss>
